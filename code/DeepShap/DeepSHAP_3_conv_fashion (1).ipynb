{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"name":"DeepSHAP_3_conv_fashion.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"YdhXgWkMoVRg"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"YdhXgWkMoVRg","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"140430d4"},"source":["import numpy as np\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","import torch.nn.functional as F\n","\n","np.random.seed(1)"],"id":"140430d4","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceb75fc4"},"source":["NUMBER_OF_CLASSES = 10\n","EPOCHS = 20\n","BATCH_SIZE = 128\n","# VALIDATION_SPLIT = 0.2"],"id":"ceb75fc4","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b5e87330"},"source":["# Load MNIST dataset\n","working_dir = '/content/drive/MyDrive/EECS 545 project/'\n","transform_list={\n","    torchvision.transforms.ToTensor(),\n","    # torchvision.transforms.Normalize(mean=(0), std=(1.0)),\n","}\n","transforms = torchvision.transforms.Compose(transform_list)\n","train_set = torchvision.datasets.FashionMNIST(train=True, root=working_dir + 'Fashion_MNIST', download = True, transform=transforms)\n","test_set = torchvision.datasets.FashionMNIST(train=False, root=working_dir + 'Fashion_MNIST', download = True, transform=transforms)"],"id":"b5e87330","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c59fa7b1"},"source":["train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=BATCH_SIZE, shuffle=False)\n","test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=BATCH_SIZE, shuffle=False)"],"id":"c59fa7b1","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"20e84ce0"},"source":["class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(4, 4), stride=(2, 2))\n","        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(4, 4), stride=(2, 2))\n","        self.drop1 = nn.Dropout(p=0.25)\n","        self.lin1 = nn.Linear(1600, 128)\n","        self.drop2 = nn.Dropout(p=0.5)\n","        self.output = nn.Linear(128, 10)\n","\n","    def forward(self, input_batch):\n","        x = F.relu(self.conv1(input_batch))\n","        x = F.relu(self.conv2(x))\n","        x = self.drop1(x)\n","        x = torch.flatten(x, start_dim=1)\n","        x = F.relu(self.lin1(x))\n","        x = self.drop2(x)\n","        x = self.output(x)\n","        return x"],"id":"20e84ce0","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"75d58c19"},"source":["device = torch.device(\"cpu\")\n","cnn_mnist= SimpleCNN().to(device)\n","cnn_mnist.load_state_dict(torch.load(working_dir + \"cnn_fashion_mnist_model_cpu.pth\"))\n","cnn_mnist.eval()"],"id":"75d58c19","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ab7b2db8"},"source":["# DeepSHAP Implementation"],"id":"ab7b2db8"},{"cell_type":"code","metadata":{"id":"G7ek0Vs50Vi2"},"source":["\"\"\"\n","Begin\n","\"\"\""],"id":"G7ek0Vs50Vi2","execution_count":null,"outputs":[]},{"cell_type":"code","source":["layers = [cnn_mnist.conv1, cnn_mnist.conv2, cnn_mnist.lin1, cnn_mnist.output]\n","num_layers = len(layers)"],"metadata":{"id":"Uoo3j9wIMh9N"},"id":"Uoo3j9wIMh9N","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Pick a sample from the test set\n","print(test_loader.dataset.class_to_idx)\n","idx = [19, 2, 1, 13, 6, 8, 4, 9, 18, 0]  # Example indices\n","fig, axs = plt.subplots(3, 4)\n","for i in range(10):\n","    features, label = test_loader.dataset.__getitem__(idx[i])\n","    # print(label)\n","    axs[i // 4, i % 4].imshow(features.squeeze(), cmap='gray', vmin=0, vmax=1)\n","index = idx[0]\n","features, label = test_loader.dataset.__getitem__(index)\n","features = features.unsqueeze(0)\n","# print(features)\n","pre_label = cnn_mnist(features).max(dim=1)[1]\n","print(\"Predict label: \", pre_label.item(), \"True label: \", label)\n","\n","fig, axs = plt.subplots(1,1)\n","axs.imshow(features.reshape(28,28), cmap='gray', vmin=0, vmax=1)"],"metadata":{"id":"lehIa8XzN7nF"},"id":"lehIa8XzN7nF","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Choose background\n","# print(test_loader.dataset.data.shape)\n","# print(test_loader.dataset.targets.shape)\n","reference_data = test_loader.dataset.data[0:1000, :, :]\n","reference_data = reference_data.unsqueeze(1) / 255.0\n","\n","# ## method 1\n","# ## Conv1\n","# conv1_ref_pre = cnn_mnist.conv1(reference_data)\n","# conv1_ref = F.relu(conv1_ref_pre)\n","# ## Conv2\n","# conv2_ref_pre = cnn_mnist.conv2(conv1_ref)\n","# conv2_ref = F.relu(conv2_ref_pre)\n","# conv2_ref_flat = torch.flatten(conv2_ref, start_dim=1)\n","# ## lin1\n","# lin1_ref_pre = cnn_mnist.lin1(conv2_ref_flat)\n","# lin1_ref = F.relu(lin1_ref_pre)\n","# ## lin2\n","# output_ref = cnn_mnist.output(lin1_ref)\n","# # print(output_ref)\n","# # output_ref_2 = cnn_mnist(reference_data)\n","# # print(output_ref_2)\n","\n","# ## Average all the refence values\n","# ref = reference_data.mean(dim=0)\n","# ## Conv1\n","# conv1_ref_pre = conv1_ref_pre.mean(dim=0)\n","# conv1_ref = conv1_ref.mean(dim=0)\n","# ## Conv2\n","# conv2_ref_pre = conv2_ref_pre.mean(dim=0)\n","# conv2_ref = conv2_ref.mean(dim=0)\n","# conv2_ref_flat = conv2_ref_flat.mean(dim=0)\n","# ## lin1\n","# lin1_ref_pre = lin1_ref_pre.mean(dim=0)\n","# lin1_ref = lin1_ref.mean(dim=0)\n","# ## lin2\n","# output_ref = output_ref.mean(dim=0)\n","\n","## method 2\n","ref = reference_data.mean(dim=0).unsqueeze(0)\n","## Conv1\n","conv1_ref_pre = cnn_mnist.conv1(ref)\n","conv1_ref = F.relu(conv1_ref_pre)\n","## Conv2\n","conv2_ref_pre = cnn_mnist.conv2(conv1_ref)\n","conv2_ref = F.relu(conv2_ref_pre)\n","conv2_ref_flat = torch.flatten(conv2_ref, start_dim=1)\n","## lin1\n","lin1_ref_pre = cnn_mnist.lin1(conv2_ref_flat)\n","lin1_ref = F.relu(lin1_ref_pre)\n","## lin2\n","output_ref = cnn_mnist.output(lin1_ref)\n","\n","fig, axs = plt.subplots(1,1)\n","axs.imshow(ref.reshape(28,28), cmap='RdBu', vmin = -1, vmax=1)"],"metadata":{"id":"trq3WZJnShOT"},"id":"trq3WZJnShOT","execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Fordward pass\n","## Conv1\n","conv1_pre = cnn_mnist.conv1(features)\n","conv1_data = F.relu(conv1_pre)\n","## Conv2\n","conv2_pre = cnn_mnist.conv2(conv1_data)\n","conv2_data = F.relu(conv2_pre)\n","conv2_flat = torch.flatten(conv2_data, start_dim=1)\n","## lin1\n","lin1_pre = cnn_mnist.lin1(conv2_flat)\n","lin1_data = F.relu(lin1_pre)\n","## lin2\n","output_data = cnn_mnist.output(lin1_data)\n","# print(output_data)\n","\n","## Calculating delta\n","x_delta = features - ref\n","## Conv1\n","delta_conv1_pre = conv1_pre - conv1_ref_pre\n","delta_conv1_data = conv1_data - conv1_ref\n","## Conv2\n","delta_conv2_pre = conv2_pre- conv2_ref_pre\n","delta_conv2_data = conv2_data - conv2_ref\n","delta_conv2_flat = conv2_flat - conv2_ref_flat\n","## lin1\n","delta_lin1_pre = lin1_pre - lin1_ref_pre\n","delta_lin1_data = lin1_data - lin1_ref\n","## lin2\n","delta_output_data = output_data - output_ref\n"],"metadata":{"id":"p5R-ZEUdShT4"},"id":"p5R-ZEUdShT4","execution_count":null,"outputs":[]},{"cell_type":"code","source":["eps = 1e-4\n","## Calculating SHAP values\n","shap_values_mul = np.zeros((NUMBER_OF_CLASSES, features.shape[2], features.shape[3]))\n","# Backward pass\n","for clas in range(NUMBER_OF_CLASSES):\n","    # output layer\n","    temp = (delta_lin1_data.data).requires_grad_(True)\n","    z = cnn_mnist.output(temp)\n","    z[0, clas].backward()\n","    delta_lin1_data_grad = temp.grad\n","    # print(delta_lin1_data_grad)\n","    # print(cnn_mnist.output.weight[clas, :])\n","\n","    # lin1 layer\n","    idx = (abs(delta_lin1_pre.data) < eps)\n","    delta_lin1_pre_grad = torch.FloatTensor(delta_lin1_pre.shape)\n","    if torch.sum(idx) != 0:\n","        for i in range(delta_lin1_pre.shape[1]):\n","            if idx[0, i] == True:\n","                temp1 = (delta_lin1_pre[0, i].data).requires_grad_(True)\n","                z = F.relu(temp1)\n","                z.backward()\n","                delta_lin1_pre_grad[0, i] = temp1.grad * delta_lin1_data_grad[0, i]\n","    if torch.sum(~idx) != 0:\n","        temp2 = delta_lin1_data[:, (~idx).squeeze()].data / delta_lin1_pre[:, (~idx).squeeze()].data\n","        temp2 = temp2 * delta_lin1_data_grad[:, (~idx).squeeze()]\n","    \n","    if torch.sum(~idx) != 0:\n","        delta_lin1_pre_grad[:, (~idx).squeeze()] = temp2\n","    # print(delta_lin1_pre_grad)\n","\n","    temp2 = torch.FloatTensor(cnn_mnist.lin1.weight.shape)\n","    for i in range(temp2.shape[0]):\n","        temp = (delta_conv2_data.data).requires_grad_(True)\n","        z = torch.flatten(temp, start_dim=1)\n","        z2 = cnn_mnist.lin1(z)\n","        z2[0, i].backward()\n","        temp2[i, :] = torch.flatten(temp.grad, start_dim=1)\n","    delta_conv2_data_grad = torch.matmul(delta_lin1_pre_grad, temp2)\n","    # print(delta_conv2_data_grad[:, 100:200])\n","    delta_conv2_data_grad = delta_conv2_data_grad.unflatten(1, delta_conv2_data.squeeze().shape)\n","    # delta_conv2_data_grad = torch.flatten(delta_conv2_data_grad, start_dim=1)\n","    # print(delta_conv2_data_grad[:, 100:200])\n","\n","    # conv2 layer\n","    idx = (abs(delta_conv2_pre.data) < eps).squeeze()\n","    delta_conv2_pre_grad = torch.FloatTensor(delta_conv2_pre.shape)\n","    if torch.sum(idx) != 0:\n","        for i in range(delta_conv2_pre.shape[1]):\n","            for j in range(delta_conv2_pre.shape[2]):\n","                for k in range(delta_conv2_pre.shape[3]):\n","                    if idx[i, j, k] == True:\n","                        temp1 = (delta_conv2_pre[0, i, j, k].data).requires_grad_(True)\n","                        z = F.relu(temp1)\n","                        z.backward()\n","                        delta_conv2_pre_grad[0, i, j, k] = temp1.grad * delta_conv2_data_grad[0, i, j, k]\n","    if torch.sum(~idx) != 0:\n","        temp2 = delta_conv2_data[:, ~idx].data / delta_conv2_pre[:, ~idx].data\n","        temp2 = temp2 * delta_conv2_data_grad[:, ~idx]\n","    # print(temp2.shape)\n","\n","    if torch.sum(~idx) != 0:\n","        delta_conv2_pre_grad[:, (~idx).squeeze()] = temp2\n","    # print(delta_conv2_pre_grad.shape)\n","    \n","    delta_conv2_pre_grad_flat = torch.flatten(delta_conv2_pre_grad, start_dim=1)\n","    # print(delta_conv2_pre_grad_flat.shape)\n","    # print(delta_conv1_data.shape)\n","    temp2 = torch.FloatTensor(delta_conv2_pre_grad_flat.shape[1], delta_conv1_data.flatten(start_dim=1).shape[1])\n","    # print(temp2.shape)\n","    \n","    for i in range(temp2.shape[0]):\n","        temp = (delta_conv1_data.data).requires_grad_(True)\n","        z2 = cnn_mnist.conv2(temp)\n","        z2.flatten(start_dim=1)[0, i].backward()\n","        temp2[i, :] = torch.flatten(temp.grad, start_dim=1)\n","    delta_conv1_data_grad = torch.matmul(delta_conv2_pre_grad_flat, temp2)\n","    # print(delta_conv1_data_grad.shape)\n","    # print(delta_conv1_data_grad[:, 100:200])\n","    delta_conv1_data_grad = delta_conv1_data_grad.unflatten(1, delta_conv1_data.squeeze().shape)\n","    # delta_conv1_data_grad = torch.flatten(delta_conv1_data_grad, start_dim=1)\n","    # print(delta_conv1_data_grad[:, 100:200])\n","\n","    # conv1 layer\n","    idx = (abs(delta_conv1_pre.data) < eps).squeeze()\n","    delta_conv1_pre_grad = torch.FloatTensor(delta_conv1_pre.shape)\n","    if torch.sum(idx) != 0:\n","        for i in range(delta_conv1_pre.shape[1]):\n","            for j in range(delta_conv1_pre.shape[2]):\n","                for k in range(delta_conv1_pre.shape[3]):\n","                    if idx[i, j, k] == True:\n","                        temp1 = (delta_conv1_pre[0, i, j, k].data).requires_grad_(True)\n","                        z = F.relu(temp1)\n","                        z.backward()\n","                        delta_conv1_pre_grad[0, i, j, k] = temp1.grad * delta_conv1_data_grad[0, i, j, k]\n","    if torch.sum(~idx) != 0:\n","        temp2 = delta_conv1_data[:, ~idx].data / delta_conv1_pre[:, ~idx].data\n","        temp2 = temp2 * delta_conv1_data_grad[:, ~idx]\n","    # print(temp2.shape)\n","\n","    if torch.sum(~idx) != 0:\n","        delta_conv1_pre_grad[:, (~idx).squeeze()] = temp2\n","    # print(delta_conv1_pre_grad.shape)\n","    \n","    delta_conv1_pre_grad_flat = torch.flatten(delta_conv1_pre_grad, start_dim=1)\n","    # print(delta_conv1_pre_grad_flat.shape)\n","    # print(x_delta.shape)\n","    temp2 = torch.FloatTensor(delta_conv1_pre_grad_flat.shape[1], x_delta.flatten(start_dim=1).shape[1])\n","    # print(temp2.shape)\n","    \n","    for i in range(temp2.shape[0]):\n","        temp = (x_delta.data).requires_grad_(True)\n","        z2 = cnn_mnist.conv1(temp)\n","        z2.flatten(start_dim=1)[0, i].backward()\n","        temp2[i, :] = torch.flatten(temp.grad, start_dim=1)\n","\n","    x_delta_grad = torch.matmul(delta_conv1_pre_grad_flat, temp2)\n","    # print(x_delta_grad.shape)\n","    # print(x_delta_grad[:, 100:200])\n","    x_delta_grad = x_delta_grad.unflatten(1, x_delta.squeeze().shape)\n","    # x_delta_grad = torch.flatten(x_delta_grad, start_dim=1)\n","    # print(x_delta_grad[:, 100:200])\n","\n","    shap_values_mul[clas, :, :] = x_delta_grad.squeeze().numpy()\n"],"metadata":{"id":"DLzKEae_Mh_f"},"id":"DLzKEae_Mh_f","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YKfDWVxfTNog"},"source":["explaination = (shap_values_mul.reshape(10, 784) * x_delta.numpy().reshape(1, 784)).T  # shape (784, 10)\n","# explaination = (shap_values_mul.reshape(10, 784) * features.numpy().reshape(1, 784)).T  # shape (784, 10)\n","print(explaination.sum(axis=0))\n","print(delta_output_data.squeeze().detach().numpy())"],"id":"YKfDWVxfTNog","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wpOonjYtdIvp"},"source":["#  Normalization\n","explaination = explaination - explaination.mean(axis=1).reshape(-1, 1)"],"id":"wpOonjYtdIvp","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Maksing\n","# for clas in range(NUMBER_OF_CLASSES):\n","#     sort_idx = np.argsort(abs(explaination[:, clas]))\n","#     mask = sort_idx[0:round(explaination.shape[0] * 0.85)]\n","#     explaination[mask, clas] = 0"],"metadata":{"id":"P3JTjjig3g8a"},"id":"P3JTjjig3g8a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BtswCf17TNws"},"source":["number_compare_list = [1, 2, 3, 4, 6]\n","name_of_class = ['Trouser', 'Pullover', 'Dress', 'Coat', 'Shirt']\n","fig, axs = plt.subplots(3, len(number_compare_list))\n","number = label\n","input_img = features.numpy().reshape(1, 784)\n","expected_X = ref.numpy().reshape(1, 784)\n","limit_common = abs(explaination).max()\n","axs[0, 0].imshow(input_img.reshape(28,28), cmap='gray', vmin=0, vmax=1)\n","axs[0, 1].imshow(expected_X.reshape(28,28), cmap='gray', vmin=0, vmax=1)\n","axs[0, 2].imshow(explaination[:, number].reshape(28,28), cmap='RdBu', vmin = -limit_common, vmax=limit_common)\n","axs[0, 0].axis(\"off\")\n","axs[0, 1].axis(\"off\")\n","axs[0, 2].axis(\"off\")\n","axs[0, 3].axis(\"off\")\n","axs[0, 4].axis(\"off\")\n","\n","for i, number_compare in enumerate(number_compare_list):\n","    # mean = explaination.mean()\n","    # axs[0].imshow(explaination[:, number].reshape(28,28), cmap='gray', vmin = explaination[:, number].min(), vmax=explaination[:, number].max())\n","    # axs[i, 0].imshow(input_img.reshape(28,28), cmap='RdBu', vmin = -1, vmax=1)\n","    # axs[i, 1].imshow(expected_X.reshape(28,28), cmap='RdBu', vmin = -1, vmax=1)\n","    # limit_common = max(abs(explaination[:, number]).max(), abs(explaination[:, number_compare]).max())\n","    # limit = abs(explaination[:, number]).max()\n","    # axs[i, 2].imshow(explaination[:, number].reshape(28,28), cmap='RdBu', vmin = -limit_common, vmax=limit_common)\n","    # limit = abs(explaination[:, number_compare]).max()\n","    axs[1, i].imshow(explaination[:, number_compare].reshape(28,28), cmap='RdBu', vmin = -limit_common, vmax=limit_common)\n","    axs[1, i].axis(\"off\")\n","    sort_idx = np.argsort(explaination[:, number_compare])\n","    mask = sort_idx[0:round(explaination.shape[0] * 0.2)]\n","    # mask = (explaination[:, number_compare] < 0)\n","    input_img_masked = input_img.copy()\n","    input_img_masked[0, mask] = 0\n","    axs[2, i].imshow(input_img_masked.reshape(28,28), cmap='gray', vmin=0, vmax=1)\n","    axs[2, i].text(6, 35, name_of_class[i])\n","    axs[2, i].axis(\"off\")\n","\n","plt.savefig(working_dir + \"fashion-mnist-cnn-relu.pdf\")\n","\n","\n","# fig, axs = plt.subplots(1,4)\n","# input_img = features.numpy().reshape(1, 784)\n","# number = label\n","# number_compare = 7\n","# # mean = explaination.mean()\n","# # axs[0].imshow(explaination[:, number].reshape(28,28), cmap='gray', vmin = explaination[:, number].min(), vmax=explaination[:, number].max())\n","# axs[0].imshow(input_img.reshape(28,28), cmap='RdBu', vmin = -1, vmax=1)\n","# limit_common = max(abs(explaination[:, number]).max(), abs(explaination[:, number_compare]).max())\n","# limit = abs(explaination[:, number]).max()\n","# axs[1].imshow(explaination[:, number].reshape(28,28), cmap='RdBu', vmin = -limit_common, vmax=limit_common)\n","# limit = abs(explaination[:, number_compare]).max()\n","# axs[2].imshow(explaination[:, number_compare].reshape(28,28), cmap='RdBu', vmin = -limit_common, vmax=limit_common)\n","# sort_idx = np.argsort(explaination[:, number_compare])\n","# mask = sort_idx[0:round(explaination.shape[0] * 0.2)]\n","# # mask = (explaination[:, number_compare] < 0)\n","# input_img_masked = input_img.copy()\n","# input_img_masked[0, mask] = 0\n","# axs[3].imshow(input_img_masked.reshape(28,28), cmap='RdBu', vmin = -1, vmax=1)\n"],"id":"BtswCf17TNws","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfJgLanaiF09"},"source":["print(explaination.max())\n","print(explaination.min())"],"id":"WfJgLanaiF09","execution_count":null,"outputs":[]},{"cell_type":"code","source":["%pip install shap\n","import shap"],"metadata":{"id":"bbPo5h3mtCGb"},"id":"bbPo5h3mtCGb","execution_count":null,"outputs":[]},{"cell_type":"code","source":["shap_values = []\n","for i in range(NUMBER_OF_CLASSES):\n","    shap_values.append(explaination[:, i].reshape(1, 28, 28, 1))"],"metadata":{"id":"acKRdSNXuc-v"},"id":"acKRdSNXuc-v","execution_count":null,"outputs":[]},{"cell_type":"code","source":["shap.image_plot(shap_values, input_img.reshape(1, 28, 28, 1))"],"metadata":{"id":"J5EwObULtCJC"},"id":"J5EwObULtCJC","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(explaination[:, number])"],"metadata":{"id":"slrPiRAfubvJ"},"id":"slrPiRAfubvJ","execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"LDXgsoBEtCLl"},"id":"LDXgsoBEtCLl","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(output_data)"],"metadata":{"id":"uUrI8Bf4tCOF"},"id":"uUrI8Bf4tCOF","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rOuOCo7RTavN"},"source":["\"\"\"\n","End\n","\"\"\""],"id":"rOuOCo7RTavN","execution_count":null,"outputs":[]}]}